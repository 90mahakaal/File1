{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2674b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Write a python program which searches all the product under a particular product from www.amazon.in. The \n",
    "product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for \n",
    "guitars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c31befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e00c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9cfc3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening site\n",
    "driver.get('https://www.amazon.in./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e90f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search bar selection\n",
    "desig=driver.find_elements(By.ID,\"twotabsearchtextbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0631e898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what would you like to search today?\n",
      "LAPTOP\n"
     ]
    }
   ],
   "source": [
    "#take input from user: Note press enter after entering the input to get out of loop\n",
    "print(\"what would you like to search today?\")\n",
    "search_for=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb832be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on search icon\n",
    "search_button=driver.find_element(By.CLASS_NAME,\"nav-search-submit nav-sprite\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf409e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de066beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2  In the above question, now scrape the following details of each product listed in first 3 pages of your search \n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then \n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand \n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and \n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“.#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "321b6582",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_name=[]\n",
    "price=[]\n",
    "product_url=[]\n",
    "expected_delivery=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb4162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. Write a python program to access the search bar and search button on images.google.com and scrape 10 \n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e06f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3a555ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c6d976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening site\n",
    "driver.get('https://images.google.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dec0e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering fruits asked by the quastion\n",
    "desig=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/textarea\")\n",
    "desig.send_keys('fruits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5e2ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the elements containing the company names\n",
    "fruits = driver.find_elements(By.XPATH, '/html/body/div[4]/div/div[13]/div/div[2]/div[2]/div/div/div/div/div[1]/div/div/div[1]/div[2]/h3/a/div/div/div')\n",
    "\n",
    "# Extract the fruits names\n",
    "top_10_fruits = [fruit.text for fruit in fruits[:10]]  # Extract top 10 companies\n",
    "\n",
    "# Print or process the extracted fruits names\n",
    "for fruits_name in top_10_fruits:\n",
    "    print(fruits)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering cars asked by the quastion\n",
    "desig=driver.find_element(By.XPATH,\"/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/textarea\")\n",
    "desig.send_keys('cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98e2960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bee6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the elements containing the company names\n",
    "cars = driver.find_elements(By.XPATH, '/html/body/div[4]/div/div[13]/div/div[2]/div[2]/div/div/div/div/div[1]/div/div/div[1]/div[2]/h3/a/div/div/div')\n",
    "\n",
    "# Extract the car names\n",
    "top_10_cars = [car.text for car in cars[:10]]  # Extract top 10 cars\n",
    "\n",
    "# Print or process the extracted car names\n",
    "for cars_name in top_10_cars:\n",
    "    print(cars)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4 Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand \n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, \n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the \n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881065d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0706a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Write a program to scrap all the available details of best gaming laptops from digit.in. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07606676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7c24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "041b675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening site\n",
    "driver.get('https://www.digit.in./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a49470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation and loc asked by the quastion\n",
    "desig=driver.find_element(By.CLASS_NAME,\"icon-search-onclick\")\n",
    "desig.send_keys('gaming laptops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc7d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[5]/div/form/input[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697ac44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_name=[]\n",
    "price=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scarping job title form the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[3]/div/div/article/div[2]/div[3]/div[1]/h3/a')\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    laptop_name.append(title)\n",
    "\n",
    "# scarping job loc form the given page\n",
    "price_tags= driver.find_elements(By.XPATH,'[class=\"price_for_grid redbrightcolor floatleft rehub-btn-font mr10\"]')\n",
    "for i in price_tags:\n",
    "    price=i.text\n",
    "    price.append(price)\n",
    "    \n",
    "# scarping comp name form the given page\n",
    "rating_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[3]/div/div/article/div[2]/div[3]/div[1]/div[3]')\n",
    "for i in rating_tags:\n",
    "    rating=i.text\n",
    "    rating.append(rating)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a6820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[3]/div/div/article/div[2]/div[3]/div[1]/div[3]')\n",
    "for i in rating_tags:\n",
    "    rating=i.text\n",
    "    rating.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255770bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7   Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: \n",
    "“Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50273d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f5efd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Edge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3213bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening site\n",
    "driver.get('https://www.forbes.com./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering billionaires asked by the quastion\n",
    "desig=driver.find_element(By.XPATH,\"/html/body/div[1]/header/nav/div[1]/div[1]/div/div[2]/ul/li[2]/div[1]\")\n",
    "desig.send_keys('billionaires')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6709b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "name=[]\n",
    "networth=[]\n",
    "age=[]\n",
    "citizenship=[]\n",
    "source=[]\n",
    "industry=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scarping rank form the given page\n",
    "rank_tags= driver.find_elements(By.XPATH,'[class=\"price_for_grid redbrightcolor floatleft rehub-btn-font mr10\"]')\n",
    "for i in rank_tags:\n",
    "    rank=i.text\n",
    "    rank.append(rank)\n",
    "    \n",
    "# scarping name form the given page\n",
    "name_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[3]/div/div/article/div[2]/div[3]/div[1]/div[3]')\n",
    "for i in name_tags:\n",
    "    name=i.text\n",
    "    name.append(name)\n",
    "    \n",
    "\n",
    "# scarping networth form the given page\n",
    "networth_tags= driver.find_elements(By.XPATH,'[class=\"price_for_grid redbrightcolor floatleft rehub-btn-font mr10\"]')\n",
    "for i in networth_tags:\n",
    "    networth=i.text\n",
    "    networth.append(networth)\n",
    "    \n",
    "# scarping age form the given page\n",
    "age_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[3]/div/div/article/div[2]/div[3]/div[1]/div[3]')\n",
    "for i in age_tags:\n",
    "    age=i.text\n",
    "    age.append(age)\n",
    "# scarping citizenship form the given page\n",
    "citizenship_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[3]/div/div/article/div[2]/div[3]/div[1]/div[3]')\n",
    "for i in citizenship_tags:\n",
    "    citizenship=i.text\n",
    "    citizenship.append(citizenship)\n",
    "    \n",
    "\n",
    "# scarping source form the given page\n",
    "source_tags= driver.find_elements(By.XPATH,'[class=\"price_for_grid redbrightcolor floatleft rehub-btn-font mr10\"]')\n",
    "for i in source_tags:\n",
    "    source=i.text\n",
    "    source.append(source)\n",
    "    \n",
    "# scarping industry form the given page\n",
    "industry_tags=driver.find_elements(By.XPATH,'/html/body/div[1]/div[3]/div/div/article/div[2]/div[3]/div[1]/div[3]')\n",
    "for i in industry_tags:\n",
    "    industry=i.text\n",
    "    industry.append(industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6398ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc46109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted \n",
    "from any YouTube Video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in \n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall \n",
    "reviews, privates from price, dorms from price, facilities and property description. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
